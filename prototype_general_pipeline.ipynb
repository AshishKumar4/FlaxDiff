{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flaxdiff.schedulers import EDMNoiseScheduler, KarrasVENoiseScheduler\n",
    "from flaxdiff.predictors import KarrasPredictionTransform\n",
    "from flaxdiff.models.simple_unet import Unet\n",
    "from flaxdiff.trainer.general_diffusion_trainer import GeneralDiffusionTrainer, ConditionalInputConfig\n",
    "from flaxdiff.data.datasets import get_dataset_grain\n",
    "from flaxdiff.utils import defaultTextEncodeModel\n",
    "from flaxdiff.models.autoencoder.diffusers import StableDiffusionVAE\n",
    "from flaxdiff.samplers.euler import EulerAncestralSampler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 13:11:02.488048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744463463.166512   23190 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744463463.483736   23190 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744463466.930492   23190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744463466.930522   23190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744463466.930524   23190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744463466.930526   23190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing FlaxCLIPTextModel: {('vision_model', 'encoder', 'layers', '12', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm2', 'bias'), ('vision_model', 'embeddings', 'position_embedding', 'embedding'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'k_proj', 'bias'), ('text_projection', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm1', 'bias'), ('vision_model', 'pre_layrnorm', 'scale'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'post_layernorm', 'scale'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm1', 'scale'), ('vision_model', 'post_layernorm', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'embeddings', 'class_embedding'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm1', 'scale'), ('vision_model', 'pre_layrnorm', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc1', 'kernel'), ('logit_scale',), ('vision_model', 'encoder', 'layers', '9', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm2', 'scale'), ('vision_model', 'embeddings', 'patch_embedding', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'out_proj', 'bias'), ('visual_projection', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'k_proj', 'bias')}\n",
      "- This IS expected if you are initializing FlaxCLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxCLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n",
      "WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor: 0.18215\n",
      "Calculating downscale factor...\n",
      "Downscale factor: 8\n",
      "Latent channels: 4\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = get_dataset_grain(\"oxford_flowers102\", batch_size=BATCH_SIZE, image_scale=IMAGE_SIZE)\n",
    "datalen = data['train_len']\n",
    "batches = datalen // BATCH_SIZE\n",
    "\n",
    "text_encoder = defaultTextEncodeModel()\n",
    "autoencoder = StableDiffusionVAE(**{\"modelname\": \"pcuenq/sd-vae-ft-mse-flax\"})\n",
    "\n",
    "# Construct a validation set by the prompts\n",
    "val_prompts = ['water tulip', ' a water lily', ' a water lily', ' a photo of a rose', ' a photo of a rose', ' a water lily', ' a water lily', ' a photo of a marigold', ' a photo of a marigold', ' a photo of a marigold', ' a water lily', ' a photo of a sunflower', ' a photo of a lotus', ' columbine', ' columbine', ' an orchid', ' an orchid', ' an orchid', ' a water lily', ' a water lily', ' a water lily', ' columbine', ' columbine', ' a photo of a sunflower', ' a photo of a sunflower', ' a photo of a sunflower', ' a photo of a lotus', ' a photo of a lotus', ' a photo of a marigold', ' a photo of a marigold', ' a photo of a rose', ' a photo of a rose', ' a photo of a rose', ' orange dahlia', ' orange dahlia', ' a lenten rose', ' a lenten rose', ' a water lily', ' a water lily', ' a water lily', ' a water lily', ' an orchid', ' an orchid', ' an orchid', ' hard-leaved pocket orchid', ' bird of paradise', ' bird of paradise', ' a photo of a lovely rose', ' a photo of a lovely rose', ' a photo of a globe-flower', ' a photo of a globe-flower', ' a photo of a lovely rose', ' a photo of a lovely rose', ' a photo of a ruby-lipped cattleya', ' a photo of a ruby-lipped cattleya', ' a photo of a lovely rose', ' a water lily', ' a osteospermum', ' a osteospermum', ' a water lily', ' a water lily', ' a water lily', ' a red rose', ' a red rose']\n",
    "\n",
    "def get_val_dataset(batch_size=8):\n",
    "    for i in range(0, len(val_prompts), batch_size):\n",
    "        prompts = val_prompts[i:i + batch_size]\n",
    "        tokens = text_encoder.tokenize(prompts)\n",
    "        yield {\"text\": tokens}\n",
    "\n",
    "data['test'] = get_val_dataset\n",
    "data['test_len'] = len(val_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "from diffusers import FlaxUNet2DConditionModel\n",
    "from flaxdiff.inputs import DiffusionInputConfig, ConditionalInputConfig\n",
    "\n",
    "input_config = DiffusionInputConfig(\n",
    "    sample_data_key='image',\n",
    "    sample_data_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    conditions=[\n",
    "        ConditionalInputConfig(\n",
    "            encoder=text_encoder,\n",
    "            conditioning_data_key='text',\n",
    "            pretokenized=True,\n",
    "            unconditional_input=\"\",\n",
    "            model_key_override=\"textcontext\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "input_shapes = input_config.get_input_shapes(\n",
    "    autoencoder=autoencoder,\n",
    ")\n",
    "\n",
    "unet_model = FlaxUNet2DConditionModel(\n",
    "    sample_size=input_shapes[\"x\"][1],  # the target image resolution\n",
    "    in_channels=input_shapes[\"x\"][2],  # the number of input channels, 3 for RGB images\n",
    "    out_channels=input_shapes[\"x\"][2],  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(64, 128, 256, 512),  # the number of output channels for each UNet block\n",
    "    cross_attention_dim=512,  # the size of the cross-attention layers\n",
    "    dtype=jnp.bfloat16,\n",
    "    use_memory_efficient_attention=True,\n",
    ")\n",
    "        \n",
    "class BCHWModelWrapper(nn.Module):\n",
    "    model: nn.Module\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, temb, textcontext):\n",
    "        # Reshape the input to BCHW format from BHWC\n",
    "        x = jnp.transpose(x, (0, 3, 1, 2))\n",
    "        # Pass the input through the UNet model\n",
    "        out = self.model(\n",
    "            sample=x,\n",
    "            timesteps=temb,\n",
    "            encoder_hidden_states=textcontext,\n",
    "        )\n",
    "        # Reshape the output back to BHWC format\n",
    "        out = jnp.transpose(out.sample, (0, 2, 3, 1))\n",
    "        return out\n",
    "    \n",
    "unet = BCHWModelWrapper(unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n"
     ]
    }
   ],
   "source": [
    "from flaxdiff.inputs import DiffusionInputConfig, ConditionalInputConfig\n",
    "\n",
    "input_config = DiffusionInputConfig(\n",
    "    sample_data_key='image',\n",
    "    sample_data_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    conditions=[\n",
    "        ConditionalInputConfig(\n",
    "            encoder=text_encoder,\n",
    "            conditioning_data_key='text',\n",
    "            pretokenized=True,\n",
    "            unconditional_input=\"\",\n",
    "            model_key_override=\"textcontext\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_shapes = input_config.get_input_shapes(\n",
    "    autoencoder=autoencoder,\n",
    ")\n",
    "\n",
    "unet = Unet(emb_features=256, \n",
    "            feature_depths=[64, 64, 128, 256, 512],\n",
    "            attention_configs=[\n",
    "                None,\n",
    "                {\"heads\":8, \"dtype\":jnp.float32, \"flash_attention\":False, \"use_projection\":False, \"use_self_and_cross\":True}, \n",
    "                {\"heads\":8, \"dtype\":jnp.float32, \"flash_attention\":False, \"use_projection\":False, \"use_self_and_cross\":True}, \n",
    "                {\"heads\":8, \"dtype\":jnp.float32, \"flash_attention\":False, \"use_projection\":False, \"use_self_and_cross\":True}, \n",
    "                {\"heads\":8, \"dtype\":jnp.float32, \"flash_attention\":False, \"use_projection\":False, \"use_self_and_cross\":False}\n",
    "            ],\n",
    "            num_res_blocks=2,\n",
    "            num_middle_res_blocks=1,\n",
    "            dtype=jnp.bfloat16,\n",
    "            output_channels=input_shapes[\"x\"][2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashishkumar4\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mrwhite0racle/persist/FlaxDiff/wandb/run-20250412_131238-ypc17dea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/umd-projects/mlops-msml605-project/runs/ypc17dea' target=\"_blank\">General_Diffusion_2025-04-12_13:12:29</a></strong> to <a href='https://wandb.ai/umd-projects/mlops-msml605-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/umd-projects/mlops-msml605-project' target=\"_blank\">https://wandb.ai/umd-projects/mlops-msml605-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/umd-projects/mlops-msml605-project/runs/ypc17dea' target=\"_blank\">https://wandb.ai/umd-projects/mlops-msml605-project/runs/ypc17dea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating states for DiffusionTrainer\n"
     ]
    }
   ],
   "source": [
    "# Define noise scheduler\n",
    "edm_schedule = EDMNoiseScheduler(1, sigma_max=80, rho=7, sigma_data=0.5)\n",
    "karas_ve_schedule = KarrasVENoiseScheduler(1, sigma_max=80, rho=7, sigma_data=0.5)\n",
    "# Define model\n",
    "\n",
    "# Define optimizer\n",
    "solver = optax.adam(2e-4)\n",
    "\n",
    "# Create the GeneralDiffusionTrainer\n",
    "experiment_name = f\"General_Diffusion_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "\n",
    "trainer = GeneralDiffusionTrainer(\n",
    "    unet,\n",
    "    optimizer=solver,\n",
    "    noise_schedule=edm_schedule,\n",
    "    autoencoder=autoencoder,\n",
    "    input_config=input_config,\n",
    "    rngs=jax.random.PRNGKey(42),\n",
    "    name=experiment_name,\n",
    "    model_output_transform=KarrasPredictionTransform(\n",
    "        sigma_data=edm_schedule.sigma_data),\n",
    "    # data_key='image',  # Specify the key for image data in batches\n",
    "    distributed_training=True,\n",
    "    wandb_config={\n",
    "        \"project\": 'mlops-msml605-project',\n",
    "        \"entity\": 'umd-projects',\n",
    "        \"name\": experiment_name,\n",
    "        \"config\": {\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"image_size\": IMAGE_SIZE,\n",
    "            \"architecture\": \"unet\",\n",
    "        }\n",
    "    },\n",
    "    native_resolution=IMAGE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1475: 600step [00:26, 22.34step/s, loss=0.5232]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1475 Loss: 0.4699305593967438\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1475 completed. Avg Loss: 0.4699305593967438, Time: 26.86s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1476/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1476:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4465]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 754236\n",
      "Training started for process index 0 at step 754236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1476: 600step [00:27, 22.20step/s, loss=0.4653]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1476 Loss: 0.46798717975616455\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1476 completed. Avg Loss: 0.46798717975616455, Time: 27.03s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1477/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1477:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5279]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 754747\n",
      "Training started for process index 0 at step 754747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1477: 600step [00:26, 22.60step/s, loss=0.5680]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1477 Loss: 0.46927326917648315\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1477 completed. Avg Loss: 0.46927326917648315, Time: 26.55s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1478/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1478:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 755258\n",
      "Training started for process index 0 at step 755258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1478: 600step [00:26, 22.45step/s, loss=0.4745]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1478 Loss: 0.46889442205429077\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1478 completed. Avg Loss: 0.46889442205429077, Time: 26.73s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1479/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1479:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 755769\n",
      "Training started for process index 0 at step 755769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1479: 600step [00:27, 22.19step/s, loss=0.4725]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1479 Loss: 0.4689628481864929\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1479 completed. Avg Loss: 0.4689628481864929, Time: 27.04s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1480/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1480:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 756280\n",
      "Training started for process index 0 at step 756280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1480: 600step [00:26, 22.30step/s, loss=0.4822]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1480 Loss: 0.46772485971450806\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1480 completed. Avg Loss: 0.46772485971450806, Time: 26.91s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1481/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1481:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4535]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 756791\n",
      "Training started for process index 0 at step 756791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1481: 600step [00:26, 22.42step/s, loss=0.4467]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1481 Loss: 0.4691937565803528\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1481 completed. Avg Loss: 0.4691937565803528, Time: 26.76s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1482/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1482:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4897]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 757302\n",
      "Training started for process index 0 at step 757302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1482: 600step [00:27, 21.87step/s, loss=0.5098]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1482 Loss: 0.468335896730423\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1482 completed. Avg Loss: 0.468335896730423, Time: 27.43s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1483/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1483:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 757813\n",
      "Training started for process index 0 at step 757813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1483: 600step [00:26, 23.01step/s, loss=0.4715]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1483 Loss: 0.47192198038101196\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1483 completed. Avg Loss: 0.47192198038101196, Time: 26.08s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 115.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1484/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1484:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5057]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 758324\n",
      "Training started for process index 0 at step 758324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1484: 600step [00:27, 21.79step/s, loss=0.4352]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1484 Loss: 0.4703725278377533\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1484 completed. Avg Loss: 0.4703725278377533, Time: 27.53s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1485/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1485:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4507]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 758835\n",
      "Training started for process index 0 at step 758835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1485: 600step [00:26, 22.49step/s, loss=0.4180]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1485 Loss: 0.4677030146121979\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1485 completed. Avg Loss: 0.4677030146121979, Time: 26.68s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1486/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1486:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4836]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 759346\n",
      "Training started for process index 0 at step 759346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1486: 600step [00:26, 22.65step/s, loss=0.4840]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1486 Loss: 0.46962007880210876\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1486 completed. Avg Loss: 0.46962007880210876, Time: 26.49s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1487/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1487:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4580]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 759857\n",
      "Training started for process index 0 at step 759857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1487: 600step [00:26, 22.42step/s, loss=0.4657]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1487 Loss: 0.46994540095329285\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1487 completed. Avg Loss: 0.46994540095329285, Time: 26.76s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1488/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1488:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5313]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 760368\n",
      "Training started for process index 0 at step 760368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1488: 600step [00:26, 22.55step/s, loss=0.4569]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1488 Loss: 0.46668046712875366\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1488 completed. Avg Loss: 0.46668046712875366, Time: 26.61s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1489/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1489:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 760879\n",
      "Training started for process index 0 at step 760879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1489: 600step [00:26, 22.28step/s, loss=0.4446]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1489 Loss: 0.46838825941085815\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1489 completed. Avg Loss: 0.46838825941085815, Time: 27.00s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1490/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1490:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4817]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 761390\n",
      "Training started for process index 0 at step 761390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1490: 600step [00:27, 21.86step/s, loss=0.4779]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1490 Loss: 0.4682980477809906\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1490 completed. Avg Loss: 0.4682980477809906, Time: 27.45s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1491/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1491:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4931]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 761901\n",
      "Training started for process index 0 at step 761901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1491: 600step [00:27, 21.89step/s, loss=0.5158]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1491 Loss: 0.4662906229496002\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1491 completed. Avg Loss: 0.4662906229496002, Time: 27.41s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1492/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1492:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4321]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 762412\n",
      "Training started for process index 0 at step 762412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1492: 600step [00:27, 21.98step/s, loss=0.4510]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1492 Loss: 0.46941182017326355\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1492 completed. Avg Loss: 0.46941182017326355, Time: 27.30s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1493/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1493:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5106]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 762923\n",
      "Training started for process index 0 at step 762923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1493: 600step [00:27, 22.03step/s, loss=0.4292]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1493 Loss: 0.47032368183135986\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1493 completed. Avg Loss: 0.47032368183135986, Time: 27.24s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1494/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1494:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 763434\n",
      "Training started for process index 0 at step 763434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1494: 600step [00:26, 22.26step/s, loss=0.4882]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1494 Loss: 0.4663403630256653\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1494 completed. Avg Loss: 0.4663403630256653, Time: 26.96s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 109.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1495/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1495:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 763945\n",
      "Training started for process index 0 at step 763945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1495: 600step [00:28, 21.42step/s, loss=0.4837]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1495 Loss: 0.46778395771980286\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1495 completed. Avg Loss: 0.46778395771980286, Time: 28.02s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 109.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1496/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1496:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 764456\n",
      "Training started for process index 0 at step 764456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1496: 600step [00:27, 22.05step/s, loss=0.4289]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1496 Loss: 0.46825721859931946\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1496 completed. Avg Loss: 0.46825721859931946, Time: 27.21s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1497/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1497:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 764967\n",
      "Training started for process index 0 at step 764967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1497: 600step [00:27, 22.04step/s, loss=0.4367]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1497 Loss: 0.46788260340690613\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1497 completed. Avg Loss: 0.46788260340690613, Time: 27.23s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 115.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1498/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1498:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4852]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 765478\n",
      "Training started for process index 0 at step 765478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1498: 600step [00:27, 22.00step/s, loss=0.4712]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1498 Loss: 0.46709874272346497\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1498 completed. Avg Loss: 0.46709874272346497, Time: 27.27s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1499/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1499:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4530]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 765989\n",
      "Training started for process index 0 at step 765989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1499: 600step [00:27, 21.66step/s, loss=0.4348]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1499 Loss: 0.46812382340431213\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1499 completed. Avg Loss: 0.46812382340431213, Time: 27.71s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 115.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1500/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1500:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5141]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 766500\n",
      "Training started for process index 0 at step 766500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1500: 600step [00:27, 21.54step/s, loss=0.4639]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1500 Loss: 0.47118183970451355\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1500 completed. Avg Loss: 0.47118183970451355, Time: 27.86s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1501/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1501:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5069]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 767011\n",
      "Training started for process index 0 at step 767011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1501: 600step [00:27, 22.03step/s, loss=0.4503]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1501 Loss: 0.4683796167373657\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1501 completed. Avg Loss: 0.4683796167373657, Time: 27.24s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1502/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1502:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4610]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 767522\n",
      "Training started for process index 0 at step 767522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1502: 600step [00:27, 21.98step/s, loss=0.4934]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1502 Loss: 0.4709969758987427\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1502 completed. Avg Loss: 0.4709969758987427, Time: 27.30s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1503/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1503:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4881]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 768033\n",
      "Training started for process index 0 at step 768033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1503: 600step [00:26, 22.23step/s, loss=0.4751]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1503 Loss: 0.4683407247066498\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1503 completed. Avg Loss: 0.4683407247066498, Time: 27.00s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1504/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1504:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5252]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 768544\n",
      "Training started for process index 0 at step 768544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1504: 600step [00:26, 22.50step/s, loss=0.4556]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1504 Loss: 0.46880778670310974\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1504 completed. Avg Loss: 0.46880778670310974, Time: 26.67s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1505/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1505:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4798]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 769055\n",
      "Training started for process index 0 at step 769055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1505: 600step [00:28, 21.32step/s, loss=0.4614]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1505 Loss: 0.46843093633651733\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1505 completed. Avg Loss: 0.46843093633651733, Time: 28.15s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1506/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1506:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 769566\n",
      "Training started for process index 0 at step 769566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1506: 600step [00:27, 22.05step/s, loss=0.4257]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1506 Loss: 0.47002676129341125\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1506 completed. Avg Loss: 0.47002676129341125, Time: 27.21s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1507/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1507:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 770077\n",
      "Training started for process index 0 at step 770077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1507: 600step [00:27, 22.09step/s, loss=0.4259]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1507 Loss: 0.46826231479644775\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1507 completed. Avg Loss: 0.46826231479644775, Time: 27.16s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1508/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1508:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 770588\n",
      "Training started for process index 0 at step 770588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1508: 600step [00:27, 22.19step/s, loss=0.3936]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1508 Loss: 0.4718356132507324\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1508 completed. Avg Loss: 0.4718356132507324, Time: 27.05s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1509/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1509:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4378]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 771099\n",
      "Training started for process index 0 at step 771099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1509: 600step [00:26, 22.32step/s, loss=0.4786]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1509 Loss: 0.46852320432662964\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1509 completed. Avg Loss: 0.46852320432662964, Time: 26.88s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1510/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1510:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 771610\n",
      "Training started for process index 0 at step 771610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1510: 600step [00:27, 21.91step/s, loss=0.4556]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1510 Loss: 0.4670238196849823\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1510 completed. Avg Loss: 0.4670238196849823, Time: 27.39s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1511/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1511:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 772121\n",
      "Training started for process index 0 at step 772121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1511: 600step [00:27, 22.15step/s, loss=0.5134]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1511 Loss: 0.46990641951560974\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1511 completed. Avg Loss: 0.46990641951560974, Time: 27.09s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1512/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1512:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 772632\n",
      "Training started for process index 0 at step 772632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1512: 600step [00:27, 22.02step/s, loss=0.4448]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1512 Loss: 0.4684750437736511\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1512 completed. Avg Loss: 0.4684750437736511, Time: 27.25s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1513:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4918]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 773143\n",
      "Training started for process index 0 at step 773143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1513: 600step [00:27, 22.01step/s, loss=0.4863]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1513 Loss: 0.46790367364883423\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1513 completed. Avg Loss: 0.46790367364883423, Time: 27.27s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1514/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1514:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4455]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 773654\n",
      "Training started for process index 0 at step 773654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1514: 600step [00:26, 22.49step/s, loss=0.4350]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1514 Loss: 0.4691774249076843\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1514 completed. Avg Loss: 0.4691774249076843, Time: 26.69s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 114.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1515/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1515:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4406]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 774165\n",
      "Training started for process index 0 at step 774165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1515: 600step [00:26, 22.78step/s, loss=0.4731]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1515 Loss: 0.4703384041786194\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1515 completed. Avg Loss: 0.4703384041786194, Time: 26.34s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 121.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1516/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1516:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5213]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 774676\n",
      "Training started for process index 0 at step 774676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1516: 600step [00:27, 21.78step/s, loss=0.4731]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1516 Loss: 0.46927598118782043\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1516 completed. Avg Loss: 0.46927598118782043, Time: 27.56s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 112.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1517/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1517:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4650]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 775187\n",
      "Training started for process index 0 at step 775187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1517: 600step [00:26, 22.39step/s, loss=0.5116]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1517 Loss: 0.46821358799934387\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1517 completed. Avg Loss: 0.46821358799934387, Time: 26.80s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1518/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1518:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4835]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 775698\n",
      "Training started for process index 0 at step 775698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1518: 600step [00:26, 22.36step/s, loss=0.4948]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1518 Loss: 0.4663558900356293\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1518 completed. Avg Loss: 0.4663558900356293, Time: 26.84s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1519/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1519:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4903]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 776209\n",
      "Training started for process index 0 at step 776209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1519: 600step [00:26, 22.31step/s, loss=0.4663]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1519 Loss: 0.4685025215148926\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1519 completed. Avg Loss: 0.4685025215148926, Time: 26.89s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1520/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1520:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4092]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 776720\n",
      "Training started for process index 0 at step 776720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1520: 600step [00:27, 22.17step/s, loss=0.5366]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1520 Loss: 0.46999451518058777\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1520 completed. Avg Loss: 0.46999451518058777, Time: 27.07s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1521/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1521:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4949]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 777231\n",
      "Training started for process index 0 at step 777231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1521: 600step [00:26, 22.24step/s, loss=0.4603]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1521 Loss: 0.4683949053287506\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1521 completed. Avg Loss: 0.4683949053287506, Time: 26.98s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 113.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1522/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1522:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4949]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 777742\n",
      "Training started for process index 0 at step 777742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1522: 600step [00:26, 22.24step/s, loss=0.5045]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1522 Loss: 0.4679831564426422\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1522 completed. Avg Loss: 0.4679831564426422, Time: 26.98s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1523/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1523:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 778253\n",
      "Training started for process index 0 at step 778253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1523: 600step [00:27, 22.01step/s, loss=0.4796]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1523 Loss: 0.4688240587711334\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1523 completed. Avg Loss: 0.4688240587711334, Time: 27.27s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1524/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1524:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4704]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 778764\n",
      "Training started for process index 0 at step 778764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1524: 600step [00:26, 22.26step/s, loss=0.4859]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1524 Loss: 0.4659760296344757\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1524 completed. Avg Loss: 0.4659760296344757, Time: 26.96s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1525/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1525:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 779275\n",
      "Training started for process index 0 at step 779275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1525: 600step [00:27, 22.18step/s, loss=0.5079]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1525 Loss: 0.46703651547431946\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1525 completed. Avg Loss: 0.46703651547431946, Time: 27.05s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1526:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4901]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 779786\n",
      "Training started for process index 0 at step 779786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1526: 600step [00:28, 21.39step/s, loss=0.4779]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1526 Loss: 0.46822288632392883\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1526 completed. Avg Loss: 0.46822288632392883, Time: 28.06s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1527/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1527:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 780297\n",
      "Training started for process index 0 at step 780297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1527: 600step [00:26, 22.31step/s, loss=0.5028]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1527 Loss: 0.46881717443466187\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1527 completed. Avg Loss: 0.46881717443466187, Time: 26.89s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1528/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1528:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4751]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 780808\n",
      "Training started for process index 0 at step 780808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1528: 600step [00:26, 22.32step/s, loss=0.5028]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1528 Loss: 0.4676021933555603\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1528 completed. Avg Loss: 0.4676021933555603, Time: 26.88s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1529/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1529:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4529]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 781319\n",
      "Training started for process index 0 at step 781319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1529: 600step [00:26, 22.32step/s, loss=0.4536]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1529 Loss: 0.4688307046890259\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1529 completed. Avg Loss: 0.4688307046890259, Time: 26.89s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1530/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1530:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 781830\n",
      "Training started for process index 0 at step 781830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1530: 600step [00:27, 22.17step/s, loss=0.5035]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1530 Loss: 0.47000652551651\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1530 completed. Avg Loss: 0.47000652551651, Time: 27.07s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1531/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1531:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 782341\n",
      "Training started for process index 0 at step 782341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1531: 600step [00:26, 22.34step/s, loss=0.4712]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1531 Loss: 0.4685263931751251\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1531 completed. Avg Loss: 0.4685263931751251, Time: 26.86s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1532/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1532:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4291]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 782852\n",
      "Training started for process index 0 at step 782852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1532: 600step [00:27, 22.08step/s, loss=0.4345]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1532 Loss: 0.4677729308605194\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1532 completed. Avg Loss: 0.4677729308605194, Time: 27.18s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 120.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1533/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1533:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4835]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 783363\n",
      "Training started for process index 0 at step 783363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1533: 600step [00:26, 22.28step/s, loss=0.4484]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1533 Loss: 0.4668722450733185\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1533 completed. Avg Loss: 0.4668722450733185, Time: 26.93s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1534/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1534:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4369]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 783874\n",
      "Training started for process index 0 at step 783874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1534: 600step [00:27, 22.08step/s, loss=0.4632]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1534 Loss: 0.4679631292819977\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1534 completed. Avg Loss: 0.4679631292819977, Time: 27.18s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1535/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1535:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4497]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 784385\n",
      "Training started for process index 0 at step 784385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1535: 600step [00:26, 22.46step/s, loss=0.4681]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1535 Loss: 0.46574872732162476\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1535 completed. Avg Loss: 0.46574872732162476, Time: 26.72s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1536/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1536:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 784896\n",
      "Training started for process index 0 at step 784896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1536: 600step [00:27, 22.13step/s, loss=0.4408]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1536 Loss: 0.4671768546104431\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1536 completed. Avg Loss: 0.4671768546104431, Time: 27.11s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1537/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1537:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 785407\n",
      "Training started for process index 0 at step 785407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1537: 600step [00:27, 22.11step/s, loss=0.4575]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1537 Loss: 0.4697463810443878\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1537 completed. Avg Loss: 0.4697463810443878, Time: 27.13s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1538/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1538:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 785918\n",
      "Training started for process index 0 at step 785918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1538: 600step [00:28, 21.28step/s, loss=0.4908]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1538 Loss: 0.46610766649246216\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1538 completed. Avg Loss: 0.46610766649246216, Time: 28.20s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1539/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1539:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 786429\n",
      "Training started for process index 0 at step 786429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1539: 600step [00:25, 23.16step/s, loss=0.5181]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1539 Loss: 0.4708362817764282\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1539 completed. Avg Loss: 0.4708362817764282, Time: 25.91s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1540/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1540:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4338]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 786940\n",
      "Training started for process index 0 at step 786940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1540: 600step [00:27, 22.18step/s, loss=0.4380]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1540 Loss: 0.4671047627925873\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1540 completed. Avg Loss: 0.4671047627925873, Time: 27.05s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 117.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1541/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1541:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 787451\n",
      "Training started for process index 0 at step 787451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1541: 600step [00:26, 22.26step/s, loss=0.4518]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1541 Loss: 0.467400461435318\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1541 completed. Avg Loss: 0.467400461435318, Time: 26.96s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1542/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1542:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 787962\n",
      "Training started for process index 0 at step 787962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1542: 600step [00:27, 22.04step/s, loss=0.5106]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1542 Loss: 0.4687298834323883\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1542 completed. Avg Loss: 0.4687298834323883, Time: 27.23s, Best Loss: 0.4655294418334961\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1543/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1543:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.5002]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 788473\n",
      "Training started for process index 0 at step 788473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1543: 600step [00:27, 21.82step/s, loss=0.4802]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1543 Loss: 0.46508604288101196\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "Saving model at epoch 1543 step 788984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:absl:[process=0][thread=write_metadata_after_commits] No metadata found for process_index=0, checkpoint_dir=/home/mrwhite0racle/persist/FlaxDiff/checkpoints/general_diffusion_2025-04-12_13:12:29/788984.orbax-checkpoint-tmp-164/default.orbax-checkpoint-tmp-165. If the checkpoint does not contain jax.Array then it is expected. If checkpoint contains jax.Array then it should lead to an error eventually; if no error is raised then it is a bug.\n",
      "WARNING:absl:[process=0][thread=async_save] No metadata found for any process_index, checkpoint_dir=/home/mrwhite0racle/persist/FlaxDiff/checkpoints/general_diffusion_2025-04-12_13:12:29/788984.orbax-checkpoint-tmp-164/default.orbax-checkpoint-tmp-165. time elapsed=8.249282836914062e-05 seconds. If the checkpoint does not contain jax.Array then it is expected. If checkpoint contains jax.Array then it should lead to an error eventually; if no error is raised then it is a bug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "\tEpoch 1543 completed. Avg Loss: 0.46508604288101196, Time: 27.50s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 114.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1544/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1544:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4768]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 788984\n",
      "Training started for process index 0 at step 788984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1544: 600step [00:27, 22.22step/s, loss=0.4652]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1544 Loss: 0.46932077407836914\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1544 completed. Avg Loss: 0.46932077407836914, Time: 27.01s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 115.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1545/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1545:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 789495\n",
      "Training started for process index 0 at step 789495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1545: 600step [00:25, 23.30step/s, loss=0.5102]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1545 Loss: 0.4684477746486664\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1545 completed. Avg Loss: 0.4684477746486664, Time: 25.76s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 121.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1546/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1546:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4899]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 790006\n",
      "Training started for process index 0 at step 790006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1546: 600step [00:26, 22.70step/s, loss=0.4653]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1546 Loss: 0.46814167499542236\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1546 completed. Avg Loss: 0.46814167499542236, Time: 26.43s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 121.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1547/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1547:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 790517\n",
      "Training started for process index 0 at step 790517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1547: 600step [00:27, 21.85step/s, loss=0.4790]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1547 Loss: 0.4689295291900635\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1547 completed. Avg Loss: 0.4689295291900635, Time: 27.47s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1548/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1548:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4479]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 791028\n",
      "Training started for process index 0 at step 791028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1548: 600step [00:26, 22.26step/s, loss=0.5068]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1548 Loss: 0.46703776717185974\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1548 completed. Avg Loss: 0.46703776717185974, Time: 26.96s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 120.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1549/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1549:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 791539\n",
      "Training started for process index 0 at step 791539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1549: 600step [00:26, 22.45step/s, loss=0.5074]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1549 Loss: 0.46821272373199463\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1549 completed. Avg Loss: 0.46821272373199463, Time: 26.73s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 118.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1550/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1550:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 792050\n",
      "Training started for process index 0 at step 792050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1550: 600step [00:26, 22.29step/s, loss=0.4429]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 1550 Loss: 0.46687814593315125\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 1550 completed. Avg Loss: 0.46687814593315125, Time: 26.92s, Best Loss: 0.46508604288101196\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 1551/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1551:   0%|                                          | 0/511 [00:00<?, ?step/s, loss=0.4530]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 792561\n",
      "Training started for process index 0 at step 792561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 1551:  98%|███████████████████████████████▎| 500/511 [00:21<00:00, 21.40step/s, loss=0.4651]Process SpawnProcess-21:\n",
      "Process SpawnProcess-25:\n",
      "Process SpawnProcess-8:\n",
      "Process SpawnProcess-20:\n",
      "Process SpawnProcess-11:\n",
      "Process SpawnProcess-29:\n",
      "Process SpawnProcess-16:\n",
      "Process SpawnProcess-18:\n",
      "Process SpawnProcess-31:\n",
      "Process SpawnProcess-17:\n",
      "Process SpawnProcess-26:\n",
      "Process SpawnProcess-23:\n",
      "Process SpawnProcess-7:\n",
      "Process SpawnProcess-27:\n",
      "Process SpawnProcess-12:\n",
      "Process SpawnProcess-5:\n",
      "Process SpawnProcess-14:\n",
      "Process SpawnProcess-19:\n",
      "Process SpawnProcess-30:\n",
      "Process SpawnProcess-10:\n",
      "Process SpawnProcess-28:\n",
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-6:\n",
      "Process SpawnProcess-15:\n",
      "Process SpawnProcess-13:\n",
      "Process SpawnProcess-32:\n",
      "Process SpawnProcess-3:\n",
      "Process SpawnProcess-24:\n",
      "Process SpawnProcess-1:\n",
      "Process SpawnProcess-4:\n",
      "Process SpawnProcess-9:\n",
      "Process SpawnProcess-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 235, in _worker_loop\n",
      "    next_element = next(element_producer)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 387, in __call__\n",
      "    yield from self._read_and_transform_data(last_seen_index)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 528, in _apply_transform\n",
      "    for input_record in input_iterator:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 518, in _apply_transform\n",
      "    for r in batch_op(input_iterator):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/operations.py\", line 152, in __call__\n",
      "    for input_record in input_iterator:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 530, in _apply_transform\n",
      "    output_record, filter_result = fn(input_record)\n",
      "                                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 497, in <lambda>\n",
      "    fn = lambda r: (record.Record(r.metadata, transform.map(r.data)), True)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/persist/FlaxDiff/flaxdiff/data/sources/tfds.py\", line 67, in map\n",
      "    image = cv2.resize(image, (image_scale, image_scale),\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m final_state = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEulerAncestralSampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_noise_schedule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkaras_ve_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/diffusion_trainer.py:356\u001b[39m, in \u001b[36mDiffusionTrainer.fit\u001b[39m\u001b[34m(self, data, training_steps_per_epoch, epochs, val_steps_per_epoch, sampler_class, sampling_noise_schedule)\u001b[39m\n\u001b[32m    351\u001b[39m local_batch_size = data[\u001b[33m'\u001b[39m\u001b[33mlocal_batch_size\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    352\u001b[39m validation_step_args = {\n\u001b[32m    353\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msampler_class\u001b[39m\u001b[33m\"\u001b[39m: sampler_class,\n\u001b[32m    354\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msampling_noise_schedule\u001b[39m\u001b[33m\"\u001b[39m: sampling_noise_schedule,\n\u001b[32m    355\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_batch_size\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_step_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_step_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/simple_trainer.py:525\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, data, train_steps_per_epoch, epochs, train_step_args, val_steps_per_epoch, validation_step_args)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/simple_trainer.py:437\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(self, train_state, train_step_fn, train_ds, train_steps_per_epoch, current_step, rng_state)\u001b[39m\n\u001b[32m    433\u001b[39m if i == 0:\n\u001b[32m    434\u001b[39m     print(f\"Training started for process index {process_index} at step {current_step}\")\n\u001b[32m    436\u001b[39m if self.distributed_training:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     # loss = jax.experimental.multihost_utils.process_allgather(loss)\n\u001b[32m    438\u001b[39m     loss = jnp.mean(loss) # Just to make sure its a scaler value\n\u001b[32m    440\u001b[39m if loss <= 1e-8 or jnp.isnan(loss) or jnp.isinf(loss):\n\u001b[32m    441\u001b[39m     # If the loss is too low or NaN/Inf, log the issue and attempt recovery\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/jax/_src/numpy/reductions.py:803\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    799\u001b[39m     size *= maybe_named_axis(a, \u001b[38;5;28;01mlambda\u001b[39;00m i: a_shape[i], \u001b[38;5;28;01mlambda\u001b[39;00m name: lax.psum(\u001b[32m1\u001b[39m, name))\n\u001b[32m    800\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m size\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m \u001b[38;5;129m@export\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(a: ArrayLike, axis: Axis = \u001b[38;5;28;01mNone\u001b[39;00m, dtype: DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    805\u001b[39m          out: \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, keepdims: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, *,\n\u001b[32m    806\u001b[39m          where: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m    807\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the mean of array elements along a given axis.\u001b[39;00m\n\u001b[32m    808\u001b[39m \n\u001b[32m    809\u001b[39m \u001b[33;03m  JAX implementation of :func:`numpy.mean`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m \u001b[33;03m           [6. ]], dtype=float32)\u001b[39;00m\n\u001b[32m    866\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _mean(a, _ensure_optional_axes(axis), dtype, out, keepdims,\n\u001b[32m    868\u001b[39m                where=where, upcast_f16_for_computation=(dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f2b1c15dc90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f4d2413fbd0, execution_count=5 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f4563d634d0, raw_cell=\"# Train the model\n",
      "final_state = trainer.fit(data, ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Btpu-v4-8/home/mrwhite0racle/persist/FlaxDiff/prototype_general_pipeline.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "MailboxClosedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMailboxClosedError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:543\u001b[39m, in \u001b[36m_WandbInit._pause_backend\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.notebook.save_ipynb():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, res)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:435\u001b[39m, in \u001b[36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Run], *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_finished\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     default_message = (\n\u001b[32m    438\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` will be ignored. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease make sure that you are using an active run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m     )\n\u001b[32m    441\u001b[39m     resolved_message = message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:387\u001b[39m, in \u001b[36m_log_to_run.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m     run_id = \u001b[38;5;28mself\u001b[39m._attach_id\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging.log_to_run(run_id):\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:425\u001b[39m, in \u001b[36m_run_decorator._attach.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    424\u001b[39m     \u001b[38;5;28mcls\u001b[39m._is_attaching = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:1147\u001b[39m, in \u001b[36mRun.log_code\u001b[39m\u001b[34m(self, root, name, include_fn, exclude_fn)\u001b[39m\n\u001b[32m   1142\u001b[39m     wandb.termwarn(\n\u001b[32m   1143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo relevant files were detected in the specified directory. No code will be logged to your run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1144\u001b[39m     )\n\u001b[32m   1145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mart\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:3351\u001b[39m, in \u001b[36mRun._log_artifact\u001b[39m\u001b[34m(self, artifact_or_path, name, type, aliases, tags, distributed_id, finalize, is_user_created, use_after_commit)\u001b[39m\n\u001b[32m   3349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.interface:\n\u001b[32m   3350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._settings._offline:\n\u001b[32m-> \u001b[39m\u001b[32m3351\u001b[39m         handle = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeliver_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m            \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m            \u001b[49m\u001b[43maliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3356\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3358\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3359\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3360\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3361\u001b[39m         artifact._set_save_handle(handle, \u001b[38;5;28mself\u001b[39m._public_api().client)\n\u001b[32m   3362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:589\u001b[39m, in \u001b[36mInterfaceBase.deliver_artifact\u001b[39m\u001b[34m(self, run, artifact, aliases, tags, history_step, is_user_created, use_after_commit, finalize)\u001b[39m\n\u001b[32m    587\u001b[39m     log_artifact.history_step = history_step\n\u001b[32m    588\u001b[39m log_artifact.staging_dir = get_staging_dir()\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:339\u001b[39m, in \u001b[36mInterfaceShared._deliver_artifact\u001b[39m\u001b[34m(self, log_artifact)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_artifact\u001b[39m(\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    336\u001b[39m     log_artifact: pb.LogArtifactRequest,\n\u001b[32m    337\u001b[39m ) -> MailboxHandle[pb.Result]:\n\u001b[32m    338\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(log_artifact=log_artifact)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:389\u001b[39m, in \u001b[36mInterfaceShared._deliver_record\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_record\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: pb.Record) -> MailboxHandle[pb.Result]:\n\u001b[32m    387\u001b[39m     mailbox = \u001b[38;5;28mself\u001b[39m._get_mailbox()\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     handle = \u001b[43mmailbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m._publish(record)\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle.map(\u001b[38;5;28;01mlambda\u001b[39;00m resp: resp.result_communicate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/mailbox/mailbox.py:68\u001b[39m, in \u001b[36mMailbox.require_response\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handles_lock:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxClosedError()\n\u001b[32m     70\u001b[39m     handle = MailboxResponseHandle(address)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles[address] = handle\n",
      "\u001b[31mMailboxClosedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "final_state = trainer.fit(data, batches, epochs=2000, sampler_class=EulerAncestralSampler, sampling_noise_schedule=karas_ve_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaxdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
